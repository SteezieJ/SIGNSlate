# SIGNSlate: ASL sing and facial emotion trnslation app
American Sign Language interpration swift IOS app using coreML for hand action and face expression classification.

This app receives a live input from the users camera. The video feed is used to identify and track the user's hands and face regions. The movement of the hand and the expression of the face is classified and the result displayed to the user. 

## Purpose of the app

## How does is work?

### The hand signs
### The facial expression recognition

## Results
The labels of the classified sign and expression are saved to determine if the non-manual feature has an effect on the meaning of the sign. 
